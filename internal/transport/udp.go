// =============================================================================
// æ–‡ä»¶: internal/transport/udp.go
// æè¿°: å¢å¼ºç‰ˆ UDP æœåŠ¡å™¨ - æ–°å¢åˆ†ç‰‡å‘é€æ”¯æŒ
// =============================================================================
package transport

import (
	"context"
	"fmt"
	"net"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"github.com/mrcgq/211/internal/congestion"
	"github.com/mrcgq/211/internal/protocol"
	"golang.org/x/sync/singleflight"
)

// =============================================================================
// å¸¸é‡å®šä¹‰
// =============================================================================

const (
	// ç¼“å†²åŒºé…ç½®
	defaultReadBufferSize  = 8 * 1024 * 1024  // 8MB é»˜è®¤
	defaultWriteBufferSize = 8 * 1024 * 1024  // 8MB é»˜è®¤
	maxBufferSize          = 64 * 1024 * 1024 // 64MB æœ€å¤§
	minBufferSize          = 2 * 1024 * 1024  // 2MB æœ€å°

	// Worker é…ç½®
	defaultWorkerQueueSize = 4096
	minWorkers             = 4
	maxWorkers             = 64
)

// =============================================================================
// ç¼“å†²åŒºé…ç½®
// =============================================================================

// BufferConfig ç¼“å†²åŒºé…ç½®
type BufferConfig struct {
	// ç›®æ ‡å¸¦å®½ (bps)ï¼Œç”¨äºè‡ªåŠ¨è®¡ç®—ç¼“å†²åŒº
	TargetBandwidth uint64

	// é¢„æœŸ RTT (ms)ï¼Œç”¨äºè®¡ç®— BDP
	ExpectedRTTMs uint32

	// æ‰‹åŠ¨æŒ‡å®šç¼“å†²åŒºå¤§å°ï¼ˆä¼˜å…ˆçº§é«˜äºè‡ªåŠ¨è®¡ç®—ï¼‰
	ReadBufferSize  int
	WriteBufferSize int

	// ç¼“å†²åŒºå€æ•°ï¼ˆç›¸å¯¹äº BDPï¼‰
	BufferMultiplier float64
}

// DefaultBufferConfig é»˜è®¤ç¼“å†²åŒºé…ç½®
func DefaultBufferConfig() *BufferConfig {
	return &BufferConfig{
		TargetBandwidth:  100 * 1024 * 1024, // 100 Mbps
		ExpectedRTTMs:    100,               // 100ms
		BufferMultiplier: 2.0,               // BDP çš„ 2 å€
	}
}

// HighBandwidthBufferConfig é«˜å¸¦å®½é…ç½® (1Gbps+)
func HighBandwidthBufferConfig() *BufferConfig {
	return &BufferConfig{
		TargetBandwidth:  1024 * 1024 * 1024, // 1 Gbps
		ExpectedRTTMs:    200,                // 200ms (è·¨å›½)
		BufferMultiplier: 2.5,
	}
}

// calculateBufferSize è®¡ç®—æ¨èç¼“å†²åŒºå¤§å°
func (c *BufferConfig) calculateBufferSize() (readSize, writeSize int) {
	// å¦‚æœæ‰‹åŠ¨æŒ‡å®šï¼Œç›´æ¥ä½¿ç”¨
	if c.ReadBufferSize > 0 && c.WriteBufferSize > 0 {
		return clampBufferSize(c.ReadBufferSize), clampBufferSize(c.WriteBufferSize)
	}

	// è®¡ç®— BDP (Bandwidth-Delay Product)
	// BDP = Bandwidth (bytes/s) Ã— RTT (s)
	bandwidthBytesPerSec := c.TargetBandwidth / 8
	rttSeconds := float64(c.ExpectedRTTMs) / 1000.0
	bdp := float64(bandwidthBytesPerSec) * rttSeconds

	// ç¼“å†²åŒº = BDP Ã— å€æ•°
	multiplier := c.BufferMultiplier
	if multiplier <= 0 {
		multiplier = 2.0
	}

	bufferSize := int(bdp * multiplier)
	bufferSize = clampBufferSize(bufferSize)

	return bufferSize, bufferSize
}

// clampBufferSize é™åˆ¶ç¼“å†²åŒºå¤§å°åœ¨åˆç†èŒƒå›´å†…
func clampBufferSize(size int) int {
	if size < minBufferSize {
		return minBufferSize
	}
	if size > maxBufferSize {
		return maxBufferSize
	}
	return size
}

// =============================================================================
// æ•°æ®ç»“æ„
// =============================================================================

// packetTask æ•°æ®åŒ…ä»»åŠ¡
type packetTask struct {
	data []byte
	addr *net.UDPAddr
}

// UDPServer å¢å¼ºç‰ˆ UDP æœåŠ¡å™¨
type UDPServer struct {
	addr     string
	handler  PacketHandler
	logLevel int

	conn   *net.UDPConn
	stopCh chan struct{}
	wg     sync.WaitGroup

	// ç¼“å†²åŒºé…ç½®
	bufferConfig *BufferConfig

	// æ‹¥å¡æ§åˆ¶
	congestion *congestion.Hysteria2Controller

	// ARQ å¢å¼ºå±‚
	arqEnabled bool
	arqManager *ARQManager

	// Worker æ± 
	workers   int
	workerChs []chan *packetTask
	workerWg  sync.WaitGroup

	// åŒ…åºå·
	nextPacketNum uint64

	// åˆ†ç‰‡ ID è®¡æ•°å™¨
	fragIDCounter uint32

	// çŠ¶æ€æ ‡å¿—
	running  int32
	started  int32
	sendOnly bool

	// ç»Ÿè®¡ä¿¡æ¯
	packetsRecv     uint64
	packetsSent     uint64
	bytesRecv       uint64
	bytesSent       uint64
	packetsDropped  uint64
	fragmentsSent   uint64 // æ–°å¢ï¼šå‘é€çš„åˆ†ç‰‡æ•°
	fragmentsRecv   uint64 // æ–°å¢ï¼šæ¥æ”¶çš„åˆ†ç‰‡æ•°

	// è¿æ¥å»ºç«‹çš„ singleflight é˜²æ­¢å¹¶å‘ç«äº‰
	connectGroup singleflight.Group

	// è¿æ¥çŠ¶æ€ç¼“å­˜
	connCache    sync.Map
	connCacheMu  sync.RWMutex
	connCacheTTL time.Duration

	mu sync.RWMutex
}

// arqConnState ARQ è¿æ¥çŠ¶æ€ç¼“å­˜
type arqConnState struct {
	conn        *ARQConn
	established bool
	lastCheck   time.Time
}

// =============================================================================
// æ„é€ å‡½æ•°
// =============================================================================

// NewUDPServer åˆ›å»º UDP æœåŠ¡å™¨
func NewUDPServer(addr string, h PacketHandler, logLevel string) *UDPServer {
	level := 1
	switch logLevel {
	case "debug":
		level = 2
	case "error":
		level = 0
	}

	workers := runtime.NumCPU() * 2
	if workers < minWorkers {
		workers = minWorkers
	}
	if workers > maxWorkers {
		workers = maxWorkers
	}

	return &UDPServer{
		addr:          addr,
		handler:       h,
		logLevel:      level,
		workers:       workers,
		stopCh:        make(chan struct{}),
		nextPacketNum: 1,
		bufferConfig:  DefaultBufferConfig(),
		connCacheTTL:  time.Second * 5,
		sendOnly:      false,
	}
}

// NewUDPServerSendOnly åˆ›å»ºä»…å‘é€æ¨¡å¼çš„ UDP æœåŠ¡å™¨
func NewUDPServerSendOnly(addr string, h PacketHandler, logLevel string) *UDPServer {
	server := NewUDPServer(addr, h, logLevel)
	server.sendOnly = true
	return server
}

// NewUDPServerWithConfig ä½¿ç”¨é…ç½®åˆ›å»º UDP æœåŠ¡å™¨
func NewUDPServerWithConfig(addr string, h PacketHandler, logLevel string, bufConfig *BufferConfig) *UDPServer {
	server := NewUDPServer(addr, h, logLevel)
	if bufConfig != nil {
		server.bufferConfig = bufConfig
	}
	return server
}

// =============================================================================
// é…ç½®æ–¹æ³•
// =============================================================================

// SetBufferConfig è®¾ç½®ç¼“å†²åŒºé…ç½®
func (s *UDPServer) SetBufferConfig(config *BufferConfig) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if config != nil {
		s.bufferConfig = config
	}
}

// SetCongestionController è®¾ç½®æ‹¥å¡æ§åˆ¶å™¨
func (s *UDPServer) SetCongestionController(cc *congestion.Hysteria2Controller) {
	s.congestion = cc
}

// EnableARQ å¯ç”¨ ARQ å¢å¼ºå±‚
func (s *UDPServer) EnableARQ(config *ARQConnConfig, handler ARQHandler) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if config == nil {
		config = DefaultARQConnConfig()
	}

	s.arqEnabled = true
	s.arqManager = NewARQManagerWithConfig(config, s.congestion, handler)
}

// =============================================================================
// å¯åŠ¨ä¸è¿è¡Œ
// =============================================================================

// Start å¯åŠ¨æœåŠ¡å™¨
func (s *UDPServer) Start(ctx context.Context) error {
	if s.sendOnly {
		return s.startSendOnly(ctx)
	}
	return s.startNormal(ctx)
}

// startSendOnly ä»…å‘é€æ¨¡å¼å¯åŠ¨
func (s *UDPServer) startSendOnly(ctx context.Context) error {
	conn, err := net.ListenUDP("udp", &net.UDPAddr{IP: net.IPv4zero, Port: 0})
	if err != nil {
		return fmt.Errorf("åˆ›å»ºå‘é€ socket å¤±è´¥: %w", err)
	}

	s.conn = conn

	_, writeSize := s.bufferConfig.calculateBufferSize()
	if err := s.conn.SetWriteBuffer(writeSize); err != nil {
		s.log(1, "å†™ç¼“å†²åŒºè®¾ç½®å¤±è´¥: %v", err)
	}

	atomic.StoreInt32(&s.running, 1)
	atomic.StoreInt32(&s.started, 1)

	s.log(1, "UDP æœåŠ¡å™¨å·²å¯åŠ¨ (SendOnly æ¨¡å¼)")
	return nil
}

// startNormal æ­£å¸¸æ¨¡å¼å¯åŠ¨
func (s *UDPServer) startNormal(ctx context.Context) error {
	addr, err := net.ResolveUDPAddr("udp", s.addr)
	if err != nil {
		return fmt.Errorf("è§£æåœ°å€: %w", err)
	}

	s.conn, err = net.ListenUDP("udp", addr)
	if err != nil {
		return fmt.Errorf("ç›‘å¬å¤±è´¥: %w", err)
	}

	if err := s.setupBuffers(); err != nil {
		s.log(1, "ç¼“å†²åŒºè®¾ç½®è­¦å‘Š: %v", err)
	}

	s.workerChs = make([]chan *packetTask, s.workers)
	for i := 0; i < s.workers; i++ {
		s.workerChs[i] = make(chan *packetTask, defaultWorkerQueueSize)
		s.workerWg.Add(1)
		go s.orderedWorker(i)
	}

	atomic.StoreInt32(&s.running, 1)
	atomic.StoreInt32(&s.started, 1)

	s.wg.Add(1)
	go s.readLoop(ctx)

	if s.congestion != nil {
		s.wg.Add(1)
		go s.congestionLoop(ctx)
	}

	s.wg.Add(1)
	go s.connCacheCleanupLoop(ctx)

	s.log(1, "UDP æœåŠ¡å™¨å·²å¯åŠ¨: %s (workers: %d, ARQ: %v, maxPayload: %d)",
		s.addr, s.workers, s.arqEnabled, protocol.MaxUDPPayloadSize)
	return nil
}

// setupBuffers è®¾ç½®ç³»ç»Ÿç¼“å†²åŒº
func (s *UDPServer) setupBuffers() error {
	readSize, writeSize := s.bufferConfig.calculateBufferSize()

	if err := s.conn.SetReadBuffer(readSize); err != nil {
		for size := readSize / 2; size >= minBufferSize; size /= 2 {
			if err := s.conn.SetReadBuffer(size); err == nil {
				s.log(1, "è¯»ç¼“å†²åŒºé™çº§è®¾ç½®ä¸º: %d bytes", size)
				readSize = size
				break
			}
		}
	}

	if err := s.conn.SetWriteBuffer(writeSize); err != nil {
		for size := writeSize / 2; size >= minBufferSize; size /= 2 {
			if err := s.conn.SetWriteBuffer(size); err == nil {
				s.log(1, "å†™ç¼“å†²åŒºé™çº§è®¾ç½®ä¸º: %d bytes", size)
				writeSize = size
				break
			}
		}
	}

	s.log(2, "ç¼“å†²åŒºé…ç½®: read=%dMB, write=%dMB",
		readSize/1024/1024, writeSize/1024/1024)

	return nil
}

// readLoop è¯»å–å¾ªç¯
func (s *UDPServer) readLoop(ctx context.Context) {
	defer s.wg.Done()

	buf := make([]byte, 65535)

	for atomic.LoadInt32(&s.running) == 1 {
		select {
		case <-ctx.Done():
			return
		case <-s.stopCh:
			return
		default:
		}

		_ = s.conn.SetReadDeadline(time.Now().Add(time.Second))
		n, addr, err := s.conn.ReadFromUDP(buf)
		if err != nil {
			if ne, ok := err.(net.Error); ok && ne.Timeout() {
				continue
			}
			select {
			case <-s.stopCh:
				return
			default:
				continue
			}
		}

		if n == 0 {
			continue
		}

		atomic.AddUint64(&s.packetsRecv, 1)
		atomic.AddUint64(&s.bytesRecv, uint64(n))

		data := make([]byte, n)
		copy(data, buf[:n])

		// æ£€æŸ¥æ˜¯å¦æ˜¯ ARQ åŒ…
		if s.arqEnabled && IsARQPacketData(data) {
			s.arqManager.HandlePacket(data, addr, s.conn)
			continue
		}

		// æ™®é€š UDP åŒ…
		workerIdx := s.hashAddr(addr) % s.workers

		select {
		case s.workerChs[workerIdx] <- &packetTask{data: data, addr: addr}:
		default:
			atomic.AddUint64(&s.packetsDropped, 1)
		}
	}
}

// orderedWorker ä¿åºå¤„ç† worker
func (s *UDPServer) orderedWorker(idx int) {
	defer s.workerWg.Done()

	for task := range s.workerChs[idx] {
		if task == nil {
			continue
		}

		if resp := s.handler.HandlePacket(task.data, task.addr); resp != nil {
			s.SendTo(resp, task.addr)
		}
	}
}

// connCacheCleanupLoop è¿æ¥ç¼“å­˜æ¸…ç†å¾ªç¯
func (s *UDPServer) connCacheCleanupLoop(ctx context.Context) {
	defer s.wg.Done()

	ticker := time.NewTicker(time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-s.stopCh:
			return
		case <-ticker.C:
			now := time.Now()
			s.connCache.Range(func(key, value interface{}) bool {
				state := value.(*arqConnState)
				if now.Sub(state.lastCheck) > s.connCacheTTL*10 {
					s.connCache.Delete(key)
				}
				return true
			})
		}
	}
}

// =============================================================================
// å‘é€æ–¹æ³•ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šæ”¯æŒåˆ†ç‰‡ï¼‰
// =============================================================================

// SendTo å‘é€æ•°æ®åˆ°æŒ‡å®šåœ°å€ï¼ˆè‡ªåŠ¨åˆ†ç‰‡ï¼‰
func (s *UDPServer) SendTo(data []byte, addr *net.UDPAddr) error {
	if s.conn == nil {
		return fmt.Errorf("è¿æ¥æœªåˆå§‹åŒ–")
	}

	// å¦‚æœ ARQ å·²å¯ç”¨ä¸”è¿æ¥å·²å»ºç«‹ï¼Œé€šè¿‡ ARQ å‘é€
	if s.arqEnabled && s.arqManager != nil && !s.sendOnly {
		if s.isARQConnEstablished(addr) {
			if conn := s.arqManager.GetConn(addr); conn != nil {
				return conn.Send(data)
			}
		}
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†ç‰‡
	if protocol.NeedsFragmentation(len(data)) {
		return s.sendFragmented(data, addr)
	}

	// ä¸éœ€è¦åˆ†ç‰‡ï¼Œç›´æ¥å‘é€
	s.sendWithCongestion(data, addr)
	return nil
}

// sendFragmented åˆ†ç‰‡å‘é€å¤§æ•°æ®åŒ…
func (s *UDPServer) sendFragmented(data []byte, addr *net.UDPAddr) error {
	// ç”Ÿæˆåˆ†ç‰‡ç»„ ID
	fragID := uint16(atomic.AddUint32(&s.fragIDCounter, 1) & 0xFFFF)

	totalLen := len(data)
	fragCount := protocol.CalculateFragmentCount(totalLen)

	if fragCount > protocol.MaxFragments {
		return fmt.Errorf("æ•°æ®å¤ªå¤§ï¼Œéœ€è¦ %d ä¸ªåˆ†ç‰‡ï¼Œè¶…è¿‡æœ€å¤§é™åˆ¶ %d",
			fragCount, protocol.MaxFragments)
	}

	s.log(2, "ğŸ“¦ åˆ†ç‰‡å‘é€: dataLen=%d, fragCount=%d, fragID=%d, to=%s",
		totalLen, fragCount, fragID, addr.String())

	// ä»åŸå§‹æ•°æ®ä¸­æå– reqIDï¼ˆå‡è®¾æ ¼å¼: Type(1) + ReqID(4) + ...ï¼‰
	var reqID uint32
	if len(data) >= 5 {
		reqID = uint32(data[1])<<24 | uint32(data[2])<<16 | uint32(data[3])<<8 | uint32(data[4])
	}

	for i := 0; i < fragCount; i++ {
		start := i * protocol.MaxFragmentDataSize
		end := start + protocol.MaxFragmentDataSize
		if end > totalLen {
			end = totalLen
		}

		fragData := data[start:end]

		// æ„å»ºåˆ†ç‰‡åŒ…
		fragPacket := protocol.BuildFragmentPacket(
			reqID,
			fragID,
			uint8(i),
			uint8(fragCount),
			fragData,
		)

		// å‘é€åˆ†ç‰‡
		s.sendWithCongestion(fragPacket, addr)
		atomic.AddUint64(&s.fragmentsSent, 1)

		s.log(2, "ğŸ“¤ åˆ†ç‰‡ %d/%d: %då­—èŠ‚ (fragID=%d)",
			i+1, fragCount, len(fragPacket), fragID)
	}

	return nil
}

// sendWithCongestion å¸¦æ‹¥å¡æ§åˆ¶çš„å‘é€
func (s *UDPServer) sendWithCongestion(data []byte, addr *net.UDPAddr) {
	packetSize := len(data)

	if s.congestion != nil {
		for !s.congestion.CanSend(packetSize) {
			time.Sleep(s.congestion.GetPacingInterval(packetSize))
		}

		pktNum := atomic.AddUint64(&s.nextPacketNum, 1) - 1
		s.congestion.OnPacketSent(pktNum, packetSize, false)
	}

	n, err := s.conn.WriteToUDP(data, addr)
	if err != nil {
		s.log(0, "âŒ WriteToUDP å¤±è´¥: %v, to=%s", err, addr.String())
		if s.congestion != nil {
			pktNum := atomic.LoadUint64(&s.nextPacketNum) - 1
			s.congestion.OnPacketLost(pktNum, packetSize)
		}
	} else {
		s.log(2, "âœ… WriteToUDP æˆåŠŸ: %då­—èŠ‚ -> %s", n, addr.String())
		atomic.AddUint64(&s.packetsSent, 1)
		atomic.AddUint64(&s.bytesSent, uint64(packetSize))
	}
}

// =============================================================================
// ARQ ç›¸å…³æ–¹æ³•
// =============================================================================

// SendViaARQ é€šè¿‡ ARQ å‘é€
func (s *UDPServer) SendViaARQ(ctx context.Context, data []byte, addr *net.UDPAddr) error {
	if !s.arqEnabled || s.arqManager == nil {
		return fmt.Errorf("ARQ æœªå¯ç”¨")
	}

	key := addr.String()

	connInterface, err, _ := s.connectGroup.Do(key, func() (interface{}, error) {
		return s.getOrCreateARQConn(ctx, addr)
	})

	if err != nil {
		return fmt.Errorf("è·å– ARQ è¿æ¥å¤±è´¥: %w", err)
	}

	conn := connInterface.(*ARQConn)
	return conn.Send(data)
}

// getOrCreateARQConn è·å–æˆ–åˆ›å»º ARQ è¿æ¥
func (s *UDPServer) getOrCreateARQConn(ctx context.Context, addr *net.UDPAddr) (*ARQConn, error) {
	key := addr.String()

	if cached, ok := s.connCache.Load(key); ok {
		state := cached.(*arqConnState)
		if state.established && state.conn != nil && state.conn.IsEstablished() {
			state.lastCheck = time.Now()
			return state.conn, nil
		}
	}

	if conn := s.arqManager.GetConn(addr); conn != nil {
		if conn.IsEstablished() {
			s.connCache.Store(key, &arqConnState{
				conn:        conn,
				established: true,
				lastCheck:   time.Now(),
			})
			return conn, nil
		}
	}

	conn, err := s.arqManager.CreateConn(s.conn, addr)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»º ARQ è¿æ¥å¤±è´¥: %w", err)
	}

	conn.Start()

	if err := conn.Connect(ctx); err != nil {
		return nil, fmt.Errorf("ARQ è¿æ¥å¤±è´¥: %w", err)
	}

	s.connCache.Store(key, &arqConnState{
		conn:        conn,
		established: true,
		lastCheck:   time.Now(),
	})

	return conn, nil
}

// isARQConnEstablished æ£€æŸ¥ ARQ è¿æ¥æ˜¯å¦å·²å»ºç«‹
func (s *UDPServer) isARQConnEstablished(addr *net.UDPAddr) bool {
	key := addr.String()

	if cached, ok := s.connCache.Load(key); ok {
		state := cached.(*arqConnState)
		if time.Since(state.lastCheck) < s.connCacheTTL {
			return state.established
		}

		if state.conn != nil {
			established := state.conn.IsEstablished()
			state.established = established
			state.lastCheck = time.Now()
			return established
		}
	}

	if conn := s.arqManager.GetConn(addr); conn != nil {
		established := conn.IsEstablished()
		s.connCache.Store(key, &arqConnState{
			conn:        conn,
			established: established,
			lastCheck:   time.Now(),
		})
		return established
	}

	return false
}

// =============================================================================
// æ‹¥å¡æ§åˆ¶å¾ªç¯
// =============================================================================

func (s *UDPServer) congestionLoop(ctx context.Context) {
	defer s.wg.Done()

	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-s.stopCh:
			return
		case <-ticker.C:
			if s.congestion != nil {
				stats := s.congestion.GetStats()
				s.log(2, "æ‹¥å¡æ§åˆ¶: cwnd=%d, brutal=%v, rate=%.2f Mbps",
					stats.CongestionWindow,
					stats.BrutalMode,
					stats.BrutalRate*8/1024/1024)
			}
		}
	}
}

// =============================================================================
// è¾…åŠ©æ–¹æ³•
// =============================================================================

func (s *UDPServer) hashAddr(addr *net.UDPAddr) int {
	hash := 0
	for _, b := range addr.IP {
		hash = hash*31 + int(b)
	}
	hash = hash*31 + addr.Port
	if hash < 0 {
		hash = -hash
	}
	return hash
}

func (s *UDPServer) GetARQManager() *ARQManager {
	return s.arqManager
}

func (s *UDPServer) IsRunning() bool {
	if atomic.LoadInt32(&s.running) != 1 {
		return false
	}
	if atomic.LoadInt32(&s.started) != 1 {
		return false
	}
	if s.conn == nil {
		return false
	}
	return true
}

func (s *UDPServer) IsSendOnly() bool {
	return s.sendOnly
}

func (s *UDPServer) OnAck(packetNumber uint64, ackedBytes int, rtt time.Duration) {
	if s.congestion != nil {
		s.congestion.OnPacketAcked(packetNumber, ackedBytes, rtt)
	}
}

func (s *UDPServer) OnPacketLost(packetNumber uint64, lostBytes int) {
	if s.congestion != nil {
		s.congestion.OnPacketLost(packetNumber, lostBytes)
	}
}

func (s *UDPServer) GetCongestionStats() *congestion.CongestionStats {
	if s.congestion != nil {
		return s.congestion.GetStats()
	}
	return nil
}

func (s *UDPServer) GetStats() map[string]uint64 {
	stats := map[string]uint64{
		"packets_recv":    atomic.LoadUint64(&s.packetsRecv),
		"packets_sent":    atomic.LoadUint64(&s.packetsSent),
		"bytes_recv":      atomic.LoadUint64(&s.bytesRecv),
		"bytes_sent":      atomic.LoadUint64(&s.bytesSent),
		"packets_dropped": atomic.LoadUint64(&s.packetsDropped),
		"fragments_sent":  atomic.LoadUint64(&s.fragmentsSent),
		"fragments_recv":  atomic.LoadUint64(&s.fragmentsRecv),
	}

	if s.arqEnabled && s.arqManager != nil {
		stats["arq_active_conns"] = uint64(s.arqManager.GetActiveConns())
		stats["arq_total_conns"] = s.arqManager.GetTotalConns()
	}

	if s.sendOnly {
		stats["send_only_mode"] = 1
	} else {
		stats["send_only_mode"] = 0
	}

	return stats
}

func (s *UDPServer) GetConn() *net.UDPConn {
	return s.conn
}

func (s *UDPServer) GetBufferStats() map[string]interface{} {
	readSize, writeSize := s.bufferConfig.calculateBufferSize()
	bdp := float64(s.bufferConfig.TargetBandwidth/8) * float64(s.bufferConfig.ExpectedRTTMs) / 1000

	return map[string]interface{}{
		"target_bandwidth_mbps": float64(s.bufferConfig.TargetBandwidth) / 1024 / 1024,
		"expected_rtt_ms":       s.bufferConfig.ExpectedRTTMs,
		"bdp_bytes":             int64(bdp),
		"read_buffer_bytes":     readSize,
		"write_buffer_bytes":    writeSize,
		"buffer_multiplier":     s.bufferConfig.BufferMultiplier,
		"send_only_mode":        s.sendOnly,
		"max_udp_payload":       protocol.MaxUDPPayloadSize,
	}
}

// =============================================================================
// åœæ­¢æ–¹æ³•
// =============================================================================

func (s *UDPServer) Stop() {
	if !atomic.CompareAndSwapInt32(&s.running, 1, 0) {
		return
	}

	close(s.stopCh)

	if !s.sendOnly {
		for _, ch := range s.workerChs {
			if ch != nil {
				close(ch)
			}
		}
		s.workerWg.Wait()
	}

	if s.arqManager != nil {
		s.arqManager.Close()
	}

	if s.conn != nil {
		s.conn.Close()
	}
	s.wg.Wait()

	s.connCache = sync.Map{}

	if s.sendOnly {
		s.log(1, "UDP æœåŠ¡å™¨å·²åœæ­¢ (SendOnly æ¨¡å¼)")
	} else {
		s.log(1, "UDP æœåŠ¡å™¨å·²åœæ­¢")
	}
}

// =============================================================================
// æ—¥å¿—æ–¹æ³•
// =============================================================================

func (s *UDPServer) log(level int, format string, args ...interface{}) {
	if level > s.logLevel {
		return
	}
	prefix := map[int]string{0: "[ERROR]", 1: "[INFO]", 2: "[DEBUG]"}[level]
	fmt.Printf("%s %s [UDP] %s\n", prefix, time.Now().Format("15:04:05"), fmt.Sprintf(format, args...))
}
